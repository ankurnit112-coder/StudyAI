{
  "timestamp": "20250924_231315",
  "use_real_data": false,
  "optimize_hyperparams": true,
  "results": {
    "Mathematics": {
      "mae": 2.7776682061725477,
      "rmse": 3.4967958662916137,
      "r2": 0.9177293944451139,
      "model_type": "ridge",
      "n_features": 25,
      "n_samples": 273
    },
    "English": {
      "mae": 2.4961273081142075,
      "rmse": 3.0201084562069473,
      "r2": 0.9538801388956635,
      "model_type": "ridge",
      "n_features": 25,
      "n_samples": 273
    },
    "Hindi": {
      "mae": 2.5460288264684867,
      "rmse": 3.188271458257282,
      "r2": 0.9462670905218767,
      "model_type": "ridge",
      "n_features": 25,
      "n_samples": 273
    },
    "Physical Education": {
      "mae": 3.129667903216226,
      "rmse": 3.9094798234506194,
      "r2": 0.918756461029125,
      "model_type": "ridge",
      "n_features": 25,
      "n_samples": 273
    },
    "Economics": {
      "mae": 8.545016541196077,
      "rmse": 10.654670503208076,
      "r2": -0.02289177936566844,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Business Studies": {
      "mae": 9.151373627282611,
      "rmse": 10.997570687437205,
      "r2": -0.08139037667996063,
      "model_type": "ridge",
      "n_features": 25,
      "n_samples": 273
    },
    "Accountancy": {
      "mae": 8.921350539933092,
      "rmse": 10.744601234628384,
      "r2": -0.05410495345902033,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "History": {
      "mae": 10.899750114084048,
      "rmse": 12.865050847226664,
      "r2": -0.007114281377339937,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Political Science": {
      "mae": 10.398702540711492,
      "rmse": 12.599178947951513,
      "r2": -0.040275691574401584,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Geography": {
      "mae": 11.27383062198696,
      "rmse": 13.429672852840904,
      "r2": -0.024970378834670015,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Physics": {
      "mae": 10.497000792856044,
      "rmse": 12.87584253497763,
      "r2": -0.14337156676720286,
      "model_type": "random_forest",
      "n_features": 25,
      "n_samples": 273
    },
    "Chemistry": {
      "mae": 9.230403186651323,
      "rmse": 11.854179906805728,
      "r2": -0.056748266373487066,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Biology": {
      "mae": 8.663608162998356,
      "rmse": 10.929387400744353,
      "r2": -0.04247242427776521,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    },
    "Computer Science": {
      "mae": 9.453282105249837,
      "rmse": 11.688424858821977,
      "r2": -0.05314617373446695,
      "model_type": "gradient_boosting",
      "n_features": 25,
      "n_samples": 273
    }
  },
  "feature_names": [
    "current_class",
    "gender_male",
    "math_avg",
    "math_std",
    "physics_avg",
    "physics_std",
    "chemistry_avg",
    "chemistry_std",
    "biology_avg",
    "biology_std",
    "english_avg",
    "english_std",
    "hindi_avg",
    "hindi_std",
    "cs_avg",
    "cs_std",
    "economics_avg",
    "economics_std",
    "unit_test_avg",
    "mid_term_avg",
    "final_avg",
    "pre_board_avg",
    "board_avg",
    "first_term_avg",
    "second_term_avg",
    "term_improvement",
    "overall_avg",
    "overall_median",
    "overall_std",
    "min_score",
    "max_score",
    "num_exams",
    "early_avg",
    "middle_avg",
    "late_avg",
    "overall_improvement",
    "num_subjects",
    "top_3_avg"
  ],
  "subjects": [
    "Mathematics",
    "English",
    "Hindi",
    "Physical Education",
    "Economics",
    "Business Studies",
    "Accountancy",
    "History",
    "Political Science",
    "Geography",
    "Physics",
    "Chemistry",
    "Biology",
    "Computer Science"
  ]
}